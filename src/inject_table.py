import re
import json
import os
from typing import List, Dict, Optional
import pymupdf
import html
from bs4 import BeautifulSoup

# ==============================================================================
# HELPER: PH√ÅT HI·ªÜN B·∫¢NG TRIVIAL 
# ==============================================================================

def is_trivial_table_html(table_html: str) -> bool:
    soup = BeautifulSoup(table_html, 'html.parser')
    cells = [cell.get_text(strip=True) for cell in soup.find_all('td')]
    
    if not cells or all(cell == "" for cell in cells):
        return True
    
    numeric_only = all(re.match(r'^[\d.,\s-]*$', cell) or cell == "" for cell in cells)
    if numeric_only:
        return True
    
    rows = soup.find_all('tr')
    if rows and all(len(row.find_all('td')) <= 1 for row in rows):
        return True
    
    return False

import re
from typing import List

def is_trivial_pdf_table(table_data: List[List[str]]) -> bool:
    """Ph√°t hi·ªán b·∫£ng trivial TRONG PDF (d√πng c√πng logic v·ªõi HTML)"""
    if not table_data:
        return True
    
    # Check for empty table
    if all(not row for row in table_data):
        return True
    
    all_cells = [cell for row in table_data for cell in row]
    non_empty = [cell for cell in all_cells if cell.strip() != ""]
    
    if not non_empty:
        return True
    
    # Check if all non-empty cells contain only numbers and basic punctuation
    numeric_only = all(re.match(r'^[\d.,\s-]*$', cell.strip()) for cell in non_empty)
    if numeric_only:
        return True
    
    # Check if all rows have only 0 or 1 columns (not really a table)
    if all(len(row) <= 1 for row in table_data):
        return True
    
    return False

# ==============================================================================
# PHASE 1: TR√çCH XU·∫§T B·∫¢NG T·ª™ PDF (GI·ªÆ NGUY√äN TH·ª® T·ª∞)
# ==============================================================================

def extract_raw_tables_from_pdf(pdf_path: str) -> List[List[List[str]]]:
    doc = pymupdf.open(pdf_path)
    all_tables = []
    
    print(f"üìÑ ƒêang tr√≠ch xu·∫•t b·∫£ng th√¥ t·ª´ PDF: {pdf_path}")
    
    for page_num, page in enumerate(doc, 1):
        tables = page.find_tables()
        if not tables:
            continue
        
        for i, table in enumerate(tables):
            raw_data = table.extract()
            clean_data = [
                [str(cell) if cell is not None else "" for cell in row]
                for row in raw_data
            ]
            all_tables.append(clean_data)
            print(f"  - Trang {page_num}, B·∫£ng {i+1}: {len(clean_data)} h√†ng, {max(len(r) for r in clean_data) if clean_data else 0} c·ªôt")
    
    doc.close()
    print(f"\n‚úÖ T·ªïng c·ªông: {len(all_tables)} b·∫£ng th√¥ t·ª´ PDF (ch∆∞a l·ªçc).")
    return all_tables

# ==============================================================================
# PHASE 2: PH√ÇN T√çCH MARKDOWN - GI·ªÆ NGUY√äN TH·ª® T·ª∞ V·ªä TR√ç
# ==============================================================================

def extract_table_positions_from_raw_md(md_content: str) -> List[Dict]:
    """Tr√≠ch xu·∫•t v·ªã tr√≠ b·∫£ng TRONG FILE G·ªêC THEO TH·ª® T·ª∞ XU·∫§T HI·ªÜN"""
    patterns = [
        r'(<table\b[^<]*(?:(?!</table>)<[^<]*)*</table>)',  # HTML table
        r'(\|.*\|(?:\n\|[-: ]+\|)+\n(?:\|.*\|\n*)+)'        # Markdown table syntax
    ]
    
    positions = []
    current_index = 0
    
    while current_index < len(md_content):
        earliest_match = None
        
        for pattern in patterns:
            regex = re.compile(pattern, re.DOTALL)
            match = regex.search(md_content, current_index)
            if match and (earliest_match is None or match.start() < earliest_match.start()):
                earliest_match = match
        
        if earliest_match is None:
            break
        
        start_pos = earliest_match.start()
        end_pos = earliest_match.end()
        table_content = earliest_match.group(0)
        is_html = table_content.startswith("<table")
        
        positions.append({
            "start_pos": start_pos,
            "end_pos": end_pos,
            "content": table_content,
            "is_html": is_html,
            "is_trivial": is_trivial_table_html(table_content) if is_html else False
        })
        
        current_index = end_pos
    
    return positions

# ==============================================================================
# PHASE 3: GH√âP B·∫¢NG PDF THEO TH·ª® T·ª∞ TUY·ªÜT ƒê·ªêI
# ==============================================================================

def merge_pdf_tables_in_order(
    pdf_tables: List[List[List[str]]],
    num_target_tables: int
) -> List[List[List[str]]]:
    """Gh√©p b·∫£ng PDF GI·ªÆ NGUY√äN TH·ª® T·ª∞ XU·∫§T HI·ªÜN"""
    non_trivial_pdf_tables = [t for t in pdf_tables if not is_trivial_pdf_table(t)]
    if not non_trivial_pdf_tables:
        return []
    
    num_pdf_tables = len(non_trivial_pdf_tables)
    if num_target_tables <= 0:
        return []
    
    merged_groups = []
    tables_per_group = max(1, num_pdf_tables // num_target_tables)
    start_idx = 0
    
    for i in range(num_target_tables):
        end_idx = min(start_idx + tables_per_group, num_pdf_tables)
        group_tables = non_trivial_pdf_tables[start_idx:end_idx]
        
        if group_tables:
            merged_table = []
            for table_idx, table in enumerate(group_tables):
                for row_idx, row in enumerate(table):
                    if table_idx > 0 and row_idx == 0 and is_header_like(row, merged_table[0] if merged_table else []):
                        continue
                    merged_table.append(row)
            merged_groups.append(merged_table)
        else:
            merged_groups.append([])
        
        start_idx = end_idx
    
    return merged_groups

def is_header_like(row: List[str], reference_header: List[str]) -> bool:
    if not reference_header or len(row) < len(reference_header):
        return False
    
    matches = 0
    for i, ref_cell in enumerate(reference_header):
        if i >= len(row):
            break
        cell = row[i].strip().lower()
        ref = ref_cell.strip().lower()
        if cell and ref and (cell == ref or ref in cell or cell in ref):
            matches += 1
    
    return matches >= len(reference_header) * 0.7

# ==============================================================================
# PHASE 4: THAY TH·∫æ B·∫¢NG THEO ƒê√öNG V·ªä TR√ç (KH√îNG ƒê·∫¢O TH·ª® T·ª∞)
# ==============================================================================

import html
from typing import List

def render_pdf_table_as_html(table_data: List[List[str]], has_header: bool = False) -> str:
    """Render b·∫£ng PDF th√†nh HTML v·ªõi ƒë·∫ßy ƒë·ªß t√≠nh nƒÉng"""
    if not table_data:
        return "<table></table>"
    
    num_cols = max(len(row) for row in table_data)
    html_lines = ['<table style="width:100%;">', "<colgroup>"]
    html_lines.extend(["<col/>"] * num_cols)
    html_lines.append("</colgroup>")
    
    # X·ª≠ l√Ω header n·∫øu c√≥
    if has_header and table_data:
        html_lines.append("<thead>")
        header_row = table_data[0]
        html_lines.append("<tr>")
        for i in range(num_cols):
            cell = header_row[i] if i < len(header_row) else ""
            cell_content = html.escape(cell.strip()) if cell.strip() else "&nbsp;"
            html_lines.append(f'<th><strong>{cell_content}</strong></th>')
        html_lines.append("</tr>")
        html_lines.append("</thead>")
        table_data = table_data[1:]  # B·ªè header row
    
    # X·ª≠ l√Ω body
    html_lines.append("<tbody>")
    for row in table_data:
        html_lines.append("<tr>")
        for i in range(num_cols):
            cell = row[i] if i < len(row) else ""
            cell_content = html.escape(cell.strip()) if cell.strip() else "&nbsp;"
            html_lines.append(f"<td>{cell_content}</td>")
        html_lines.append("</tr>")
    
    html_lines.append("</tbody></table>")
    return "\n".join(html_lines)

def replace_tables_in_correct_order(
    md_content: str,
    table_positions: List[Dict],
    merged_tables: List[List[List[str]]]
) -> str:
    """
    THAY TH·∫æ B·∫¢NG THEO ƒê√öNG TH·ª® T·ª∞ T·ª™ TR√äN XU·ªêNG D∆Ø·ªöI:
    1. Chu·∫©n b·ªã danh s√°ch replacement tr∆∞·ªõc
    2. Thay th·∫ø T·ª™ CU·ªêI L√äN ƒê·∫¶U ƒë·ªÉ tr√°nh l·ªách index
    3. ƒê·∫£m b·∫£o th·ª© t·ª± b·∫£ng kh√¥ng ƒë·ªïi
    """
    # B∆∞·ªõc 1: Chu·∫©n b·ªã replacement cho t·ª´ng v·ªã tr√≠ b·∫£ng
    replacements = []
    merged_idx = 0
    
    for pos in table_positions:
        if pos["is_trivial"]:
            replacements.append("")  # X√≥a b·∫£ng trivial
        else:
            if merged_idx < len(merged_tables):
                replacements.append(render_pdf_table_as_html(merged_tables[merged_idx]))
                merged_idx += 1
            else:
                replacements.append(pos["content"])  # Gi·ªØ nguy√™n n·∫øu kh√¥ng ƒë·ªß b·∫£ng PDF
    
    # B∆∞·ªõc 2: Thay th·∫ø t·ª´ cu·ªëi l√™n ƒë·∫ßu (ƒë·ªÉ kh√¥ng l·ªách index)
    result = md_content
    for i in range(len(table_positions) - 1, -1, -1):
        pos = table_positions[i]
        replacement = replacements[i]
        result = result[:pos["start_pos"]] + replacement + result[pos["end_pos"]:]
    
    return result

# ==============================================================================
# MAIN PIPELINE (ƒê·∫¢M B·∫¢O TH·ª® T·ª∞ TUY·ªÜT ƒê·ªêI)
# ==============================================================================

def process_document(
    md_path: str,
    pdf_path: str,
    output_md_path: str,
    audit_path: Optional[str] = None
):
    """Pipeline ch√≠nh - ƒê·∫¢M B·∫¢O TH·ª® T·ª∞ T·ª™ TR√äN XU·ªêNG D∆Ø·ªöI"""
    # B∆∞·ªõc 1: ƒê·ªçc file Markdown G·ªêC
    with open(md_path, "r", encoding="utf-8") as f:
        md_content = f.read()
    
    # B∆∞·ªõc 2: Tr√≠ch xu·∫•t v·ªã tr√≠ b·∫£ng THEO TH·ª® T·ª∞ XU·∫§T HI·ªÜN
    table_positions = extract_table_positions_from_raw_md(md_content)
    
    if not table_positions:
        print("‚ùó Kh√¥ng t√¨m th·∫•y b·∫£ng. Gi·ªØ nguy√™n file g·ªëc.")
        os.makedirs(os.path.dirname(output_md_path), exist_ok=True)
        with open(output_md_path, "w", encoding="utf-8") as f:
            f.write(md_content)
        return
    
    # B∆∞·ªõc 3: ƒê·∫øm s·ªë b·∫£ng KH√îNG TRIVIAL
    non_trivial_positions = [pos for pos in table_positions if not pos["is_trivial"]]
    num_target_tables = len(non_trivial_positions)
    
    # B∆∞·ªõc 4: X·ª≠ l√Ω tr∆∞·ªùng h·ª£p t·∫•t c·∫£ b·∫£ng ƒë·ªÅu trivial
    if num_target_tables == 0:
        print("‚ùó T·∫•t c·∫£ b·∫£ng ƒë·ªÅu trivial. X√≥a to√†n b·ªô b·∫£ng.")
        final_content = replace_tables_in_correct_order(md_content, table_positions, [])
        os.makedirs(os.path.dirname(output_md_path), exist_ok=True)
        with open(output_md_path, "w", encoding="utf-8") as f:
            f.write(final_content)
        return
    
    # B∆∞·ªõc 5: Tr√≠ch xu·∫•t b·∫£ng t·ª´ PDF
    pdf_tables = extract_raw_tables_from_pdf(pdf_path)
    if not pdf_tables:
        print("‚ùó Kh√¥ng c√≥ b·∫£ng trong PDF. Gi·ªØ nguy√™n file g·ªëc.")
        os.makedirs(os.path.dirname(output_md_path), exist_ok=True)
        with open(output_md_path, "w", encoding="utf-8") as f:
            f.write(md_content)
        return
    
    # B∆∞·ªõc 6: Gh√©p b·∫£ng PDF THEO TH·ª® T·ª∞
    merged_tables = merge_pdf_tables_in_order(pdf_tables, num_target_tables)
    if not merged_tables:
        print("‚ùó Kh√¥ng c√≥ b·∫£ng h·ª£p l·ªá sau khi gh√©p. Gi·ªØ nguy√™n file g·ªëc.")
        os.makedirs(os.path.dirname(output_md_path), exist_ok=True)
        with open(output_md_path, "w", encoding="utf-8") as f:
            f.write(md_content)
        return
    
    # B∆∞·ªõc 7: Thay th·∫ø v√†o file g·ªëc THEO ƒê√öNG V·ªä TR√ç
    final_content = replace_tables_in_correct_order(md_content, table_positions, merged_tables)
    
    # B∆∞·ªõc 8: L∆∞u k·∫øt qu·∫£
    os.makedirs(os.path.dirname(output_md_path), exist_ok=True)
    with open(output_md_path, "w", encoding="utf-8") as f:
        f.write(final_content)
    
    # B∆∞·ªõc 9: Audit log
    if audit_path:
        audit_data = {
            "total_md_tables": len(table_positions),
            "trivial_md_tables": len(table_positions) - num_target_tables,
            "non_trivial_md_tables": num_target_tables,
            "total_pdf_tables": len(pdf_tables),
            "merged_tables_count": len(merged_tables),
            "table_mapping": [
                {
                    "md_position": i+1,
                    "start": pos["start_pos"],
                    "end": pos["end_pos"],
                    "is_trivial": pos["is_trivial"],
                    "used_pdf_table": bool(not pos["is_trivial"] and i < len(merged_tables))
                }
                for i, pos in enumerate(table_positions)
            ]
        }
        os.makedirs(os.path.dirname(audit_path), exist_ok=True)
        with open(audit_path, "w", encoding="utf-8") as f:
            json.dump(audit_data, f, ensure_ascii=False, indent=2)
    
    print(f"\n‚úÖ HO√ÄN T·∫§T! K·∫øt qu·∫£ ƒë√£ gi·ªØ nguy√™n th·ª© t·ª± t·ª´ tr√™n xu·ªëng d∆∞·ªõi.")
    print(f"üìÅ File k·∫øt qu·∫£: {output_md_path}")

def process_single_document(md_path: str, pdf_path: str, audit_path: Optional[str] = None):
    """X·ª≠ l√Ω m·ªôt t√†i li·ªáu duy nh·∫•t - D√ôNG ƒê·ªÇ GHI ƒê√à FILE G·ªêC"""
    try:
        # B∆∞·ªõc 1: ƒê·ªçc file Markdown g·ªëc
        with open(md_path, "r", encoding="utf-8") as f:
            md_content = f.read()
        
        # B∆∞·ªõc 2: Tr√≠ch xu·∫•t v·ªã tr√≠ b·∫£ng
        table_positions = extract_table_positions_from_raw_md(md_content)
        if not table_positions:
            print(f"‚ÑπÔ∏è  B·ªè qua {os.path.basename(md_path)}: Kh√¥ng c√≥ b·∫£ng")
            return False
        
        # B∆∞·ªõc 3: X·ª≠ l√Ω b·∫£ng trivial
        non_trivial_positions = [pos for pos in table_positions if not pos["is_trivial"]]
        num_target_tables = len(non_trivial_positions)
        
        if num_target_tables == 0:
            print(f"‚ÑπÔ∏è  B·ªè qua {os.path.basename(md_path)}: T·∫•t c·∫£ b·∫£ng ƒë·ªÅu trivial")
            # X√≥a to√†n b·ªô b·∫£ng trivial
            final_content = replace_tables_in_correct_order(md_content, table_positions, [])
            with open(md_path, "w", encoding="utf-8") as f:
                f.write(final_content)
            return True
        
        # B∆∞·ªõc 4: Tr√≠ch xu·∫•t b·∫£ng t·ª´ PDF
        if not os.path.exists(pdf_path):
            print(f"‚ö†Ô∏è  B·ªè qua {os.path.basename(md_path)}: File PDF kh√¥ng t·ªìn t·∫°i: {pdf_path}")
            return False
        
        pdf_tables = extract_raw_tables_from_pdf(pdf_path)
        if not pdf_tables:
            print(f"‚ö†Ô∏è  B·ªè qua {os.path.basename(md_path)}: PDF kh√¥ng c√≥ b·∫£ng")
            return False
        
        # B∆∞·ªõc 5: Gh√©p b·∫£ng theo th·ª© t·ª±
        merged_tables = merge_pdf_tables_in_order(pdf_tables, num_target_tables)
        if not merged_tables:
            print(f"‚ö†Ô∏è  B·ªè qua {os.path.basename(md_path)}: Kh√¥ng t·∫°o ƒë∆∞·ª£c b·∫£ng h·ª£p l·ªá")
            return False
        
        # B∆∞·ªõc 6: Thay th·∫ø v√†o file g·ªëc
        final_content = replace_tables_in_correct_order(md_content, table_positions, merged_tables)
        
        # B∆∞·ªõc 7: GHI ƒê√à TR·ª∞C TI·∫æP V√ÄO FILE G·ªêC
        with open(md_path, "w", encoding="utf-8") as f:
            f.write(final_content)
        
        # B∆∞·ªõc 8: Audit log
        if audit_path:
            os.makedirs(os.path.dirname(audit_path), exist_ok=True)
            audit_data = {
                "source_md": md_path,
                "source_pdf": pdf_path,
                "total_tables": len(table_positions),
                "trivial_tables": len(table_positions) - num_target_tables,
                "processed_tables": num_target_tables,
                "pdf_tables_used": len(merged_tables),
                "processing_time": os.path.getmtime(md_path)
            }
            with open(audit_path, "w", encoding="utf-8") as f:
                json.dump(audit_data, f, ensure_ascii=False, indent=2)
        
        print(f"‚úÖ Ho√†n t·∫•t: {os.path.basename(md_path)}")
        return True
    
    except Exception as e:
        print(f"‚ùå L·ªói x·ª≠ l√Ω {md_path}: {str(e)}")
        return False
    
def process_all_folders(
    md_base_dir: str,
    pdf_base_dir: str,
    audit_base_dir: Optional[str] = None
):
    """
    X·ª¨ L√ù T·ª∞ ƒê·ªòNG T·∫§T C·∫¢ TH∆Ø M·ª§C:
    - Duy·ªát t·∫•t c·∫£ th∆∞ m·ª•c trong md_base_dir
    - T·ª± ƒë·ªông √°nh x·∫° v·ªõi file PDF t∆∞∆°ng ·ª©ng
    - Ghi ƒë√® k·∫øt qu·∫£ tr·ª±c ti·∫øp v√†o main.md g·ªëc
    """
    print(f"\n{'='*50}")
    print(f"üöÄ B·∫ÆT ƒê·∫¶U X·ª¨ L√ù TO√ÄN B·ªò TH∆Ø M·ª§C")
    print(f"üìÅ Th∆∞ m·ª•c Markdown: {md_base_dir}")
    print(f"üìÅ Th∆∞ m·ª•c PDF: {pdf_base_dir}")
    print(f"üìÅ Th∆∞ m·ª•c Audit: {audit_base_dir or 'Kh√¥ng l∆∞u'}")
    print(f"{'='*50}\n")
    
    # L·∫•y danh s√°ch t·∫•t c·∫£ th∆∞ m·ª•c con
    all_folders = [
        d for d in os.listdir(md_base_dir)
        if os.path.isdir(os.path.join(md_base_dir, d))
    ]
    
    if not all_folders:
        print("‚ùó Kh√¥ng t√¨m th·∫•y th∆∞ m·ª•c n√†o ƒë·ªÉ x·ª≠ l√Ω")
        return
    
    print(f"üìÇ T·ªïng s·ªë th∆∞ m·ª•c: {len(all_folders)}")
    print(f"Danh s√°ch: {', '.join(all_folders[:5])}{'...' if len(all_folders) > 5 else ''}\n")
    
    success_count = 0
    total_count = 0
    
    for folder_name in sorted(all_folders):
        total_count += 1
        print(f"\n{'-'*40}")
        print(f"üîÑ X·ª≠ l√Ω th∆∞ m·ª•c: {folder_name} ({total_count}/{len(all_folders)})")
        
        # ƒê∆∞·ªùng d·∫´n file
        md_path = os.path.join(md_base_dir, folder_name, "main.md")
        pdf_path = os.path.join(pdf_base_dir, f"{folder_name}.pdf")
        audit_path = os.path.join(audit_base_dir, folder_name, "audit.json") if audit_base_dir else None
        
        # Ki·ªÉm tra t·ªìn t·∫°i file
        if not os.path.exists(md_path):
            print(f"‚ùå B·ªè qua: File main.md kh√¥ng t·ªìn t·∫°i t·∫°i {md_path}")
            continue
        
        # X·ª≠ l√Ω t·ª´ng t√†i li·ªáu
        if process_single_document(md_path, pdf_path, audit_path):
            success_count += 1
    
    # B√°o c√°o t·ªïng k·∫øt
    print(f"\n{'='*50}")
    print(f"üìä B√ÅO C√ÅO T·ªîNG K·∫æT")
    print(f"T·ªïng s·ªë th∆∞ m·ª•c: {total_count}")
    print(f"‚úÖ X·ª≠ l√Ω th√†nh c√¥ng: {success_count}")
    print(f"‚ùå X·ª≠ l√Ω th·∫•t b·∫°i: {total_count - success_count}")
    print(f"{'='*50}")

if __name__ == "__main__":
    BASE_DIR = "working"
    MD_BASE_DIR = f"{BASE_DIR}/output_mineru_test"    # Th∆∞ m·ª•c ch·ª©a t·∫•t c·∫£ th∆∞ m·ª•c Public_XXX
    PDF_BASE_DIR = f"{BASE_DIR}/cleaned_pdfs_test"     # Th∆∞ m·ª•c ch·ª©a t·∫•t c·∫£ file PDF
    AUDIT_BASE_DIR = f"{BASE_DIR}/audit_logs"           # Th∆∞ m·ª•c l∆∞u audit logs (t√πy ch·ªçn)
    
    # T·∫°o th∆∞ m·ª•c audit n·∫øu c·∫ßn
    if AUDIT_BASE_DIR:
        os.makedirs(AUDIT_BASE_DIR, exist_ok=True)
        print(f"üìÅ ƒê√£ t·∫°o th∆∞ m·ª•c audit: {AUDIT_BASE_DIR}")
    
    # CH·∫†Y TO√ÄN B·ªò QUY TR√åNH
    process_all_folders(
        md_base_dir=MD_BASE_DIR,
        pdf_base_dir=PDF_BASE_DIR,
        audit_base_dir=AUDIT_BASE_DIR
    )
    
    print("\n‚ú® HO√ÄN T·∫§T TO√ÄN B·ªò QUY TR√åNH X·ª¨ L√ù!")